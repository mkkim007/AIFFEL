{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[E-04]MakeAlyricist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMwaIUoFSIBoXmLj1bykaAw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkkim007/AIFFEL/blob/main/%5BE_04%5DMakeAlyricist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0rEZATqhTVM"
      },
      "source": [
        "# [E-04] 작사가 만들기 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvmbDuFMxdFR"
      },
      "source": [
        "![](https://d3s0tskafalll9.cloudfront.net/media/images/E-12-RNN2.max-800x600.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pq5fKCgvWxj"
      },
      "source": [
        "$n−1$개의 단어 시퀀스 $w_1, \\cdots, w_{n-1}$\n",
        "​\n",
        " 가 주어졌을 때, $n$번째 단어 $w_n$ \n",
        "​\n",
        "  으로 무엇이 올지를 예측하는 확률 모델을 언어 모델(Language Model) 이라고 부릅니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQKnqLK2pJaF"
      },
      "source": [
        "import os, re \n",
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyPcGXA3xq3g"
      },
      "source": [
        "##1.데이터 준비하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBUuDKxyhQqb"
      },
      "source": [
        "### 1.1구글 드라이브 연동"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhpuZ0Kugvmv",
        "outputId": "135c5d0f-cb6a-4f5e-ca6f-94fe36bdab1c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6XTV-6eyboc"
      },
      "source": [
        "### 1.2 데이터 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2OrIr7kkAry"
      },
      "source": [
        "!mkdir -p lyricist/data/lyrics\n",
        "!cp /content/gdrive/MyDrive/Data/lyrics.zip /content/lyricist/data/\n",
        "!unzip -qq '/content/lyricist/data/lyrics.zip' -d /content/lyricist/data/lyrics"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpviW7YGlg1B",
        "outputId": "851925f0-3baa-4244-f5ad-755ed5920665"
      },
      "source": [
        "\n",
        "txt_file_path = '/content/lyricist/data/lyrics/*'\n",
        "\n",
        "txt_list = glob.glob(txt_file_path)\n",
        "\n",
        "raw_corpus = []\n",
        "\n",
        "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
        "for txt_file in txt_list:\n",
        "    with open(txt_file, \"r\") as f:\n",
        "        raw = f.read().splitlines()\n",
        "        raw_corpus.extend(raw)\n",
        "\n",
        "print(\"데이터 크기:\", len(raw_corpus))\n",
        "print(\"Examples:\\n\", raw_corpus[:3])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "데이터 크기: 187088\n",
            "Examples:\n",
            " ['Just before our love got lost you said', 'I am as constant as a northern star\" and I said', 'Constantly in the darkness']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ENRlMHDy8hV"
      },
      "source": [
        "###1.3 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFLtvHnO0XgY"
      },
      "source": [
        "####1.3.1 정제와 정규화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSbkQ25A0zDB"
      },
      "source": [
        "- 정제 : 갖고있는 코퍼스로부터 노이즈를 제거한다  \n",
        "- 정규화 : 표현 방법이 다른 단어들을 통합시켜서 같은 단어로 만들어 준다.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk3afm0Dn68c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83d61672-795c-48a4-994d-cdba055fc4dd"
      },
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    #입력된 문장을\n",
        "    # 1. [Chorus] 같은 문장을 지웁니다\n",
        "    # 2. 소문자로 바꾸고, 양쪽 공백을 지웁니다\n",
        "    # 3. 특수문자 양쪽에 공백을 넣고\n",
        "    # 4. 여러개의 공백은 하나의 공백으로 바꿉니다\n",
        "    # 5. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿉니다\n",
        "    # 6. 다시 양쪽 공백을 지웁니다\n",
        "    # 7. 문장 시작에는 <start>, 끝에는 <end>를 추가합니다\n",
        "    \n",
        "    #sentence = re.sub(r'\\[[^)]*\\]',r'',sentence ) # 1\n",
        "    sentence = sentence.lower().strip() # 2\n",
        "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 3\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 4\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 5\n",
        "    sentence = sentence.strip() # 6\n",
        "    if sentence : \n",
        "      sentence = '<start> ' + sentence + ' <end>' # 7\n",
        "      return sentence\n",
        "\n",
        "\n",
        "print(preprocess_sentence(\"[Chorus]HiHi my name is mk~!~!\"))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> chorus hihi my name is mk ! ! <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_xibUYfoi31",
        "outputId": "5f535a8d-eef3-4307-af58-0d78f347e7a1"
      },
      "source": [
        "corpus = []\n",
        "for sentence in raw_corpus:\n",
        "    \n",
        "    if len(sentence) == 0: continue\n",
        "    \n",
        "    # 정제를 해주세요 \n",
        "    preprocessed_sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    # 정제를 하고 났을때 그냥 빈 (<start><end>) sentence 들은 빼주세요! \n",
        "    if not preprocessed_sentence : continue\n",
        "    \n",
        "    #preprocessing 하고 나서 15개 이상인 것들만 담아 줬어요\n",
        "    if len(preprocessed_sentence.split(' ')) > 15 : continue\n",
        "    corpus.append(preprocessed_sentence)\n",
        "        \n",
        "# 정제된 결과를 10개만 확인해보죠\n",
        "corpus[:10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> just before our love got lost you said <end>',\n",
              " '<start> i am as constant as a northern star and i said <end>',\n",
              " '<start> constantly in the darkness <end>',\n",
              " '<start> where s that at <end>',\n",
              " '<start> in the blue tv screen light <end>',\n",
              " '<start> i drew a map of canada <end>',\n",
              " '<start> oh canada <end>',\n",
              " '<start> you taste so bitter <end>',\n",
              " '<start> but you taste so sweet oh <end>',\n",
              " '<start> still be on my feet <end>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WArO0NDG54mx"
      },
      "source": [
        "####1.3.2 토큰화 및 패딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA0bchKMqdG9",
        "outputId": "3cbbb383-19fb-4692-8f18-4aa24ef2103b"
      },
      "source": [
        "def tokenize(corpus):\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "        num_words= 12000,                  #단어장 크기는 12,000 이상!\n",
        "        filters=' ',\n",
        "        oov_token=\"<unk>\"\n",
        "    )\n",
        "    \n",
        "    # corpus를 이용해 tokenizer 내부의 단어장을 완성합니다\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환합니다\n",
        "    tensor = tokenizer.texts_to_sequences(corpus)  \n",
        "    print(tensor) \n",
        "    # 입력 데이터의 시퀀스 길이를 일정하게 맞춰줍니다\n",
        "    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다.\n",
        "    # 문장 앞에 패딩을 붙여 길이를 맞추고 싶다면 padding='pre'를 사용합니다\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=15)  \n",
        "\n",
        "    print(tensor,tokenizer)\n",
        "    return tensor, tokenizer\n",
        "\n",
        "tensor, tokenizer = tokenize(corpus)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[   2   32  173 ...    0    0    0]\n",
            " [   2    4  152 ...    3    0    0]\n",
            " [   2 3836   14 ...    0    0    0]\n",
            " ...\n",
            " [   2   42    6 ...    0    0    0]\n",
            " [   2   31    7 ...    0    0    0]\n",
            " [   2  301    1 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7fa669238410>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr7iac7aynmL",
        "outputId": "210f8745-8478-4e5f-b402-eddfab767e3a"
      },
      "source": [
        "tensor[0]\n",
        "tensor.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156174, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AI0L3Udu1VA",
        "outputId": "eadb284f-4ea8-437c-c8cc-95a9285a0079"
      },
      "source": [
        "for idx in tokenizer.index_word:\n",
        "    print(idx, \":\", tokenizer.index_word[idx])\n",
        "\n",
        "    if idx >= 10: break"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 : <unk>\n",
            "2 : <start>\n",
            "3 : <end>\n",
            "4 : i\n",
            "5 : ,\n",
            "6 : the\n",
            "7 : you\n",
            "8 : and\n",
            "9 : a\n",
            "10 : to\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZG1QK6E63QB"
      },
      "source": [
        "####1.3.3 train data와 validation data 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Szts7Xa7CHxS",
        "outputId": "c1579cdd-8ca6-438b-9957-5eddf5b8a607"
      },
      "source": [
        "# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다\n",
        "# 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n",
        "src_input = tensor[:, :-1]  \n",
        "# tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
        "tgt_input = tensor[:, 1:]    \n",
        "\n",
        "print(src_input[0])\n",
        "print(tgt_input[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  2  32 173 149  36  37 319   7 117   3   0   0   0   0]\n",
            "[ 32 173 149  36  37 319   7 117   3   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vB-S_4jyDtBl",
        "outputId": "81745bf7-7b8d-48dc-e679-30d57fcbab8a"
      },
      "source": [
        "BUFFER_SIZE = len(src_input)\n",
        "BATCH_SIZE = 256\n",
        "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
        "\n",
        " # tokenizer가 구축한 단어사전 내 7000개와, 여기 포함되지 않은 0:<pad>를 포함하여 7001개\n",
        "VOCAB_SIZE = tokenizer.num_words + 1   \n",
        "\n",
        "# 준비한 데이터 소스로부터 데이터셋을 만듭니다\n",
        "# 데이터셋에 대해서는 아래 문서를 참고하세요\n",
        "# 자세히 알아둘수록 도움이 많이 되는 중요한 문서입니다\n",
        "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
        "\n",
        "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input,test_size=0.2, random_state=42)\n",
        "print(\"Source Train:\", enc_train.shape)\n",
        "print(\"Target Train:\", dec_train.shape)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "\n",
        "# val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val))\n",
        "# val_dataset = val_dataset.shuffle(BUFFER_SIZE)\n",
        "# val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source Train: (124939, 14)\n",
            "Target Train: (124939, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFFcs98p8bNx"
      },
      "source": [
        "## 2.학습시키기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4lhIAmB96DR"
      },
      "source": [
        "###2.2 모델 구성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5CrVJPw8z8j"
      },
      "source": [
        "val_loss < 2.2 라는 루브릭 기준을 위해,, 수많은 노력을 했습니다만,,, 젤 좋은건 그냥 기존의 모델에서 파라미터 조정,,,,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17o5bvS1Kg11"
      },
      "source": [
        "class TextGenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "        #self.bidirectional_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(hidden_size,  return_sequences=True))\n",
        "        #self.bidirectional_2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(hidden_size//2,  return_sequences=True))\n",
        "        #self.linear_1 = tf.keras.layers.Dense(64, activation='relu')\n",
        "        \n",
        "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        #self.dropout = tf.keras.layers.Dropout(0.3)\n",
        "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        #self.rnn_3 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)  #층을 추가해도 오히려 loss가 올라갔습니다 ㅜ\n",
        "        #self.dropout = tf.keras.layers.Dropout(0.5)\n",
        "        self.linear_2 = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        #out = self.bidirectional_1(out)\n",
        "        #out = self.bidirectional_2(out)\n",
        "        #out = self.linear_1(out)\n",
        "        out = self.rnn_1(out)\n",
        "        \n",
        "        #out = self.rnn_3(out)\n",
        "        #out = self.dropout(out)\n",
        "        out = self.rnn_2(out)\n",
        "        out = self.linear_2(out)\n",
        "        \n",
        "        #out = self.linear(out)\n",
        "        \n",
        "        return out\n",
        "    \n",
        "embedding_size = 2048\n",
        "hidden_size = 2048\n",
        "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s82sKsDe9CjG"
      },
      "source": [
        "`self.bidirecttional` 모델을 추가하면 `val_loss`가 1epoch 에 바로 1점대로 가버렸는데, overfiting 된 것인지 작사를 시키면 단어하나만 뱉었습니다.. 또 dropout도 사용해봤는데 시간만 오래걸리고 성능은 오히려 더 안좋았습니다. 그래서 원래 기존의 모델 lstm에서 파라미터 값들만 바꾸어 학습시켜주었습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR0aeBVsy7Nt",
        "outputId": "8b4eee33-e4c1-4993-f068-d1cae20b051f"
      },
      "source": [
        "# 데이터셋에서 데이터 한 배치만 불러오는 방법입니다.\n",
        "for src_sample, tgt_sample in train_dataset.take(1): break\n",
        "\n",
        "# 한 배치만 불러온 데이터를 모델에 넣어봅니다\n",
        "model(src_sample)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 14, 7001), dtype=float32, numpy=\n",
              "array([[[-1.3354406e-03,  4.6626548e-04, -8.4370514e-04, ...,\n",
              "          2.7902934e-04,  5.2088246e-05,  3.5844478e-04],\n",
              "        [-1.4626409e-03,  7.7872974e-04, -1.0680066e-03, ...,\n",
              "          3.4858976e-04, -3.7736798e-04,  4.0633942e-04],\n",
              "        [-1.4769903e-03,  1.1813912e-04, -1.7113298e-03, ...,\n",
              "          1.1918668e-04, -5.9409480e-04, -3.9296446e-04],\n",
              "        ...,\n",
              "        [-2.5939785e-03,  1.4340694e-03,  5.5114408e-03, ...,\n",
              "         -1.4129772e-03, -1.1542095e-03, -3.3075789e-03],\n",
              "        [-2.5223803e-03,  2.6130304e-03,  6.3272896e-03, ...,\n",
              "         -2.1568174e-03, -1.6131357e-03, -3.3772443e-03],\n",
              "        [-2.4568266e-03,  3.7807995e-03,  7.0330449e-03, ...,\n",
              "         -2.8351520e-03, -2.1154424e-03, -3.5106316e-03]],\n",
              "\n",
              "       [[-1.3354406e-03,  4.6626548e-04, -8.4370514e-04, ...,\n",
              "          2.7902934e-04,  5.2088246e-05,  3.5844478e-04],\n",
              "        [-1.1529541e-03,  6.6739914e-04, -1.2093845e-03, ...,\n",
              "          6.1187096e-04,  5.2703609e-04,  6.8395020e-04],\n",
              "        [-5.9272064e-04,  3.5646834e-04, -1.9535916e-03, ...,\n",
              "          1.0049395e-03,  6.6685498e-05,  9.8770775e-04],\n",
              "        ...,\n",
              "        [ 3.7606440e-03, -5.3011454e-03,  3.9562960e-03, ...,\n",
              "          1.0333882e-03,  8.8179897e-04, -5.5189184e-06],\n",
              "        [ 2.9052068e-03, -5.3432290e-03,  3.6220576e-03, ...,\n",
              "          1.3742949e-03,  8.4915740e-04,  7.0368941e-04],\n",
              "        [ 1.6426693e-03, -4.6056737e-03,  3.0487769e-03, ...,\n",
              "          1.9228025e-03,  7.1160874e-04, -1.2634206e-04]],\n",
              "\n",
              "       [[-1.3354406e-03,  4.6626548e-04, -8.4370514e-04, ...,\n",
              "          2.7902934e-04,  5.2088246e-05,  3.5844478e-04],\n",
              "        [-3.0557662e-03,  4.0412697e-04, -1.1584199e-03, ...,\n",
              "          2.3332496e-04,  5.2302585e-05,  1.3450683e-04],\n",
              "        [-4.3966263e-03,  4.2069986e-04, -6.5256836e-04, ...,\n",
              "          5.4796477e-04,  4.9038397e-05, -3.4184432e-05],\n",
              "        ...,\n",
              "        [-1.1946568e-03,  1.4553119e-03,  1.2714403e-03, ...,\n",
              "         -3.2175251e-04, -1.9803676e-03, -2.2162466e-04],\n",
              "        [-1.2841303e-03,  1.9716478e-03,  2.0731897e-03, ...,\n",
              "         -9.5789670e-04, -2.3009656e-03, -6.0524582e-04],\n",
              "        [-1.4039543e-03,  2.6055865e-03,  2.9335441e-03, ...,\n",
              "         -1.6060102e-03, -2.6489068e-03, -1.0007068e-03]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-1.3354406e-03,  4.6626548e-04, -8.4370514e-04, ...,\n",
              "          2.7902934e-04,  5.2088246e-05,  3.5844478e-04],\n",
              "        [-1.0553923e-03,  8.0945704e-04, -6.8698841e-04, ...,\n",
              "          1.2599153e-03, -1.4872776e-04,  3.9734013e-04],\n",
              "        [-7.0160854e-04,  6.0995889e-04, -9.7896380e-04, ...,\n",
              "          2.3463813e-03, -7.6492637e-04, -1.9440013e-04],\n",
              "        ...,\n",
              "        [-3.1501646e-03,  1.1500648e-03, -1.5019986e-04, ...,\n",
              "          2.5219340e-03, -9.8674349e-04,  3.0829069e-05],\n",
              "        [-3.3331057e-03,  1.5193535e-03, -4.0140733e-04, ...,\n",
              "          2.7605216e-03, -6.8726792e-04, -1.4514483e-03],\n",
              "        [-3.6185910e-03,  1.8741147e-03, -1.1908639e-04, ...,\n",
              "          2.2262891e-03, -7.1003765e-04, -2.1747281e-03]],\n",
              "\n",
              "       [[-1.3354406e-03,  4.6626548e-04, -8.4370514e-04, ...,\n",
              "          2.7902934e-04,  5.2088246e-05,  3.5844478e-04],\n",
              "        [-2.0450598e-03,  6.9471222e-04, -2.1598414e-03, ...,\n",
              "          2.4010018e-04, -4.9023732e-04,  5.8728072e-04],\n",
              "        [-1.9951805e-03,  1.3442771e-03, -2.6431815e-03, ...,\n",
              "          4.0027880e-04, -9.3323796e-04,  6.8458851e-04],\n",
              "        ...,\n",
              "        [-1.3075185e-03,  3.0488065e-03,  5.8469624e-04, ...,\n",
              "         -1.3686063e-03, -1.6152526e-03, -2.8781237e-03],\n",
              "        [-1.5891932e-03,  3.6484455e-03,  1.8030636e-03, ...,\n",
              "         -2.1364102e-03, -1.8565541e-03, -3.0777759e-03],\n",
              "        [-1.8004772e-03,  4.3197526e-03,  3.0116306e-03, ...,\n",
              "         -2.9106860e-03, -2.1430685e-03, -3.2215375e-03]],\n",
              "\n",
              "       [[-1.3354406e-03,  4.6626548e-04, -8.4370514e-04, ...,\n",
              "          2.7902934e-04,  5.2088246e-05,  3.5844478e-04],\n",
              "        [-2.5278861e-03, -1.1848864e-04, -7.9583359e-04, ...,\n",
              "         -1.2436930e-04, -2.2135512e-04,  2.9789432e-04],\n",
              "        [-3.0103382e-03, -1.1088925e-04, -9.8392868e-04, ...,\n",
              "         -7.6003530e-04, -3.2396792e-04,  1.1417454e-04],\n",
              "        ...,\n",
              "        [-4.6899128e-03,  1.2071694e-03, -7.7930681e-04, ...,\n",
              "         -1.6631117e-03, -1.1055132e-03, -2.9857862e-03],\n",
              "        [-4.7046179e-03,  2.2988142e-03,  6.9344009e-04, ...,\n",
              "         -2.7159057e-03, -1.6346220e-03, -3.3166273e-03],\n",
              "        [-4.5746919e-03,  3.4546650e-03,  2.1039913e-03, ...,\n",
              "         -3.6327976e-03, -2.1680933e-03, -3.5755669e-03]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OG21_TCubKZz",
        "outputId": "d09fb8ef-459b-47c3-dcfb-7245edcdd265"
      },
      "source": [
        "model.summary() "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"text_generator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        multiple                  14338048  \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  multiple                  33562624  \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                multiple                  33562624  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  14345049  \n",
            "=================================================================\n",
            "Total params: 95,808,345\n",
            "Trainable params: 95,808,345\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bEJl0iM-XKY"
      },
      "source": [
        "###2.2 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hR-yJgzLc0u",
        "outputId": "7c221024-f69d-4767-d8b3-48d60254a1bb"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer,metrics=['accuracy'])\n",
        "history = model.fit(enc_train, dec_train, epochs=7, batch_size=256, validation_data=(enc_val, dec_val), verbose=1)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "489/489 [==============================] - 518s 1s/step - loss: 3.0216 - accuracy: 0.5187 - val_loss: 2.7020 - val_accuracy: 0.5431\n",
            "Epoch 2/7\n",
            "489/489 [==============================] - 516s 1s/step - loss: 2.5271 - accuracy: 0.5581 - val_loss: 2.4653 - val_accuracy: 0.5677\n",
            "Epoch 3/7\n",
            "489/489 [==============================] - 509s 1s/step - loss: 2.2062 - accuracy: 0.5924 - val_loss: 2.2913 - val_accuracy: 0.5941\n",
            "Epoch 4/7\n",
            "489/489 [==============================] - 509s 1s/step - loss: 1.8854 - accuracy: 0.6361 - val_loss: 2.1641 - val_accuracy: 0.6183\n",
            "Epoch 5/7\n",
            "489/489 [==============================] - 509s 1s/step - loss: 1.5840 - accuracy: 0.6864 - val_loss: 2.0800 - val_accuracy: 0.6414\n",
            "Epoch 6/7\n",
            "489/489 [==============================] - 510s 1s/step - loss: 1.3348 - accuracy: 0.7343 - val_loss: 2.0424 - val_accuracy: 0.6582\n",
            "Epoch 7/7\n",
            "489/489 [==============================] - 510s 1s/step - loss: 1.1548 - accuracy: 0.7725 - val_loss: 2.0381 - val_accuracy: 0.6674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrmuxBXc_QMz"
      },
      "source": [
        "data_set으로 묶어서 넣어주는 것보다 그냥 따로 넣어주는게 더 성능이 좋아서 따로 넣어 주었습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv0rM_r0-zxc"
      },
      "source": [
        "##3.평가하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnmb-TX9L0_0"
      },
      "source": [
        "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
        "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
        "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
        "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
        "    end_token = tokenizer.word_index[\"<end>\"]\n",
        "\n",
        "    # 단어 하나씩 예측해 문장을 만듭니다\n",
        "    #    1. 입력받은 문장의 텐서를 입력합니다\n",
        "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
        "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
        "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다\n",
        "    while True:\n",
        "        # 1\n",
        "        predict = model(test_tensor) \n",
        "        # 2\n",
        "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
        "        # 3 \n",
        "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
        "        # 4\n",
        "        if predict_word.numpy()[0] == end_token: break\n",
        "        if test_tensor.shape[1] >= max_len: break\n",
        "\n",
        "    generated = \"\"\n",
        "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
        "    for word_index in test_tensor[0].numpy():\n",
        "        generated += tokenizer.index_word[word_index] + \" \"\n",
        "\n",
        "    return generated"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9sClUfJTOsIj",
        "outputId": "166e1ec0-da73-40ab-c6c7-c0782479ca88"
      },
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> i\", max_len=20)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<start> i m gonna be a little selfish boom , boom , baby <end> '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQC9xxUviVmn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9e3885df-8380-47bc-9c95-7e4023d8ff68"
      },
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> i wish\", max_len=20)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<start> i wish there was a treaty <end> '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PJGKYq4beJw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "98292a65-c7e2-457c-90da-f7f63ac5f8ba"
      },
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> who\", max_len=20)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<start> who s that chick ? who s that chick ? <end> '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "F1N8TU9hbSzJ",
        "outputId": "3f0ca409-c03d-4637-8add-f932995b912a"
      },
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> when\", max_len=20)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<start> when i m not around <end> '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "ZyQ3ZA9xpjOn",
        "outputId": "40edd5f0-2528-49ae-9755-5480f7d34e8a"
      },
      "source": [
        "def plot_graphs(history, metric):\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.plot(history.history['val_'+metric], '')\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([metric, 'val_'+metric])\n",
        "  plt.show()\n",
        "plot_graphs(history, 'loss')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lgg2ucIu_b0W"
      },
      "source": [
        "--- "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmzqucWh-75X"
      },
      "source": [
        "## 🤔회고록🤔"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iT9CipEqE_z"
      },
      "source": [
        "- 루브릭... 2.2 누가 만든걸까요.. 2.2를위해서 힘을 너무 많이 뺐더닌 회고록에 쓸 힘이 남아있지않네요,,, 노드 제출후에 좀더 손을 봐야할 것 같습니다.\n",
        "- val_loss가 2.7, 2.6인 모델이 2.2인모델 보다 훨씬 문장도 잘 만듭니다. val_loss가 낮다고 절대 좋은 모델이 아니라고 생각했으나 선웅님께서 일반적으로는 참인 명제이며 문제 정의를 어떻게 하냐,,가 중요하다고 하셨습니다. \n",
        "- 아직 모델에서 파라미터(ex. embedding size)들이 어떤역할을 하는지 몰라서 너무 랜덤적으로 값을 넣어서 해봤습니다. \n",
        "- 랜덤적으로 넣고 돌리는데 한번 학습시키는데 한시간은 넘게 걸리니,,, 실험하는 데에만 너무 많은 시간을 써버렸습니다.\n",
        "- 딥러닝쪽은 항상 CV쪽만 했었는데 NLP를 해보니까 너무 어렵고 제길이 아니라는 것을 깨달았습니다. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Mu2A4HHBkOA"
      },
      "source": [
        "제가 시도한,, 많은,, 모델들중,, 모델의 summary,,, #은 valloss 값 입니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-s_2aN4LUmsy",
        "outputId": "3215cd5a-444f-4569-93b0-c67b4bdb7af5"
      },
      "source": [
        "model.summary() #2.4160"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"text_generator_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      multiple                  10240512  \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                multiple                  6295552   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                multiple                  8392704   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  20501025  \n",
            "=================================================================\n",
            "Total params: 45,429,793\n",
            "Trainable params: 45,429,793\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIxKvNUR5I4x",
        "outputId": "ce4b55e0-f0a5-4010-991a-539bb7c1f51e"
      },
      "source": [
        "model.summary() #2.5061"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"text_generator_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     multiple                  10240512  \n",
            "_________________________________________________________________\n",
            "lstm_18 (LSTM)               multiple                  6295552   \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             multiple                  20501025  \n",
            "=================================================================\n",
            "Total params: 37,037,089\n",
            "Trainable params: 37,037,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Htbd4lzY3fgr",
        "outputId": "377e7c05-c8f9-4b5f-98f9-7275609d3c72"
      },
      "source": [
        "model.summary()     #2.4497"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"text_generator_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     multiple                  10240512  \n",
            "_________________________________________________________________\n",
            "lstm_17 (LSTM)               multiple                  6295552   \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             multiple                  20501025  \n",
            "=================================================================\n",
            "Total params: 37,037,089\n",
            "Trainable params: 37,037,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmzAVAVcLL10",
        "outputId": "a4a23edb-db3c-4117-ab28-0d0c91e78499"
      },
      "source": [
        "model.summary()    #2.6248 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"text_generator_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      multiple                  10240512  \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                multiple                  6295552   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                multiple                  8392704   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  20501025  \n",
            "=================================================================\n",
            "Total params: 45,429,793\n",
            "Trainable params: 45,429,793\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}