{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[E-04]MakeAlyricist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN7AGR575uNa+5Fliwx43eV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkkim007/AIFFEL/blob/main/%5BE_04%5DMakeAlyricist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0rEZATqhTVM"
      },
      "source": [
        "# [E-04] 작사가 만들기 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQKnqLK2pJaF"
      },
      "source": [
        "import os, re \n",
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBUuDKxyhQqb"
      },
      "source": [
        "구글 드라이브 연동"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhpuZ0Kugvmv",
        "outputId": "018c2f5d-ee8a-48a7-a974-d03276f9e511"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2OrIr7kkAry"
      },
      "source": [
        "!mkdir -p lyricist/data/lyrics\n",
        "!cp /content/gdrive/MyDrive/Data/lyrics.zip /content/lyricist/data/\n",
        "!unzip -qq '/content/lyricist/data/lyrics.zip' -d /content/lyricist/data/lyrics"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpviW7YGlg1B",
        "outputId": "bb6ecbfc-9ebc-41c9-e578-b359b0d26f74"
      },
      "source": [
        "\n",
        "txt_file_path = '/content/lyricist/data/lyrics/*'\n",
        "\n",
        "txt_list = glob.glob(txt_file_path)\n",
        "\n",
        "raw_corpus = []\n",
        "\n",
        "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
        "for txt_file in txt_list:\n",
        "    with open(txt_file, \"r\") as f:\n",
        "        raw = f.read().splitlines()\n",
        "        raw_corpus.extend(raw)\n",
        "\n",
        "print(\"데이터 크기:\", len(raw_corpus))\n",
        "print(\"Examples:\\n\", raw_corpus[:3])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "데이터 크기: 187088\n",
            "Examples:\n",
            " ['Looking for some education', 'Made my way into the night', 'All that bullshit conversation']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk3afm0Dn68c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daed9c6f-8560-4b06-c320-fdaeba2fb9d1"
      },
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    #입력된 문장을\n",
        "    # 1. [Chorus] 같은 문장을 지웁니다\n",
        "    # 2. 소문자로 바꾸고, 양쪽 공백을 지웁니다\n",
        "    # 3. 특수문자 양쪽에 공백을 넣고\n",
        "    # 4. 여러개의 공백은 하나의 공백으로 바꿉니다\n",
        "    # 5. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿉니다\n",
        "    # 6. 다시 양쪽 공백을 지웁니다\n",
        "    # 7. 문장 시작에는 <start>, 끝에는 <end>를 추가합니다\n",
        "    \n",
        "    sentence = re.sub(r'\\[[^)]*\\]',r'',sentence ) # 1\n",
        "    sentence = sentence.lower().strip() # 2\n",
        "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 3\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 4\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 5\n",
        "    sentence = sentence.strip() # 6\n",
        "    if sentence : \n",
        "      sentence = '<start> ' + sentence + ' <end>' # 7\n",
        "      return sentence\n",
        "\n",
        "\n",
        "print(preprocess_sentence(\"[Chorus]HiHi my name is mk~!~!\"))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> hihi my name is mk ! ! <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_xibUYfoi31",
        "outputId": "cc917b03-2a25-4821-8622-fb5b453b9f08"
      },
      "source": [
        "corpus = []\n",
        "for sentence in raw_corpus:\n",
        "    \n",
        "    if len(sentence) == 0: continue\n",
        "    \n",
        "    # 정제를 해주세요 \n",
        "    preprocessed_sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    # 정제를 하고 났을때 그냥 빈 (<start><end>) sentence 들은 빼주세요! \n",
        "    if not preprocessed_sentence : continue\n",
        "    \n",
        "    #preprocessing 하고 나서 15개 이상인 것들만 담아 줬어요\n",
        "    if len(preprocessed_sentence.split(' ')) > 15 : continue\n",
        "    corpus.append(preprocessed_sentence)\n",
        "        \n",
        "# 정제된 결과를 10개만 확인해보죠\n",
        "corpus[:10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> looking for some education <end>',\n",
              " '<start> made my way into the night <end>',\n",
              " '<start> all that bullshit conversation <end>',\n",
              " '<start> i don t even wanna waste your time <end>',\n",
              " '<start> let s just say that maybe <end>',\n",
              " '<start> you could help me ease my mind <end>',\n",
              " '<start> if that s love in your eyes <end>',\n",
              " '<start> it s more than enough <end>',\n",
              " '<start> had some bad love <end>',\n",
              " '<start> ooh , ooh looking for some affirmation <end>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA0bchKMqdG9",
        "outputId": "21dc2931-9092-4c1a-a3cd-249a0e66fb0d"
      },
      "source": [
        "def tokenize(corpus):\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "        num_words= 20000,                  #단어장 크기는 12,000 이상!\n",
        "        filters=' ',\n",
        "        oov_token=\"<unk>\"\n",
        "    )\n",
        "    # 토큰화 했을 때 토큰의 개수가 15개를 넘어가는 문장을 학습 데이터에서 제외하기\n",
        "    # corpus를 이용해 tokenizer 내부의 단어장을 완성합니다\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환합니다\n",
        "    tensor = tokenizer.texts_to_sequences(corpus)  \n",
        "    print(tensor) \n",
        "    # 입력 데이터의 시퀀스 길이를 일정하게 맞춰줍니다\n",
        "    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다.\n",
        "    # 문장 앞에 패딩을 붙여 길이를 맞추고 싶다면 padding='pre'를 사용합니다\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=15)  \n",
        "\n",
        "    print(tensor,tokenizer)\n",
        "    return tensor, tokenizer\n",
        "\n",
        "tensor, tokenizer = tokenize(corpus)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[  2 290  28 ...   0   0   0]\n",
            " [  2 219  13 ...   0   0   0]\n",
            " [  2  25  15 ...   0   0   0]\n",
            " ...\n",
            " [  2   6 458 ...  26 205   3]\n",
            " [  2   8  41 ...   0   0   0]\n",
            " [  2   4  92 ...   0   0   0]] <keras_preprocessing.text.Tokenizer object at 0x7f9a28667990>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr7iac7aynmL",
        "outputId": "d9b69420-9f6c-43bd-8afa-94726503e40e"
      },
      "source": [
        "tensor[0]\n",
        "tensor.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(155717, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AI0L3Udu1VA",
        "outputId": "c0b44c89-ac2f-46d0-b1e6-8a020b925a0f"
      },
      "source": [
        "for idx in tokenizer.index_word:\n",
        "    print(idx, \":\", tokenizer.index_word[idx])\n",
        "\n",
        "    if idx >= 10: break"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 : <unk>\n",
            "2 : <start>\n",
            "3 : <end>\n",
            "4 : i\n",
            "5 : ,\n",
            "6 : the\n",
            "7 : you\n",
            "8 : and\n",
            "9 : a\n",
            "10 : to\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Szts7Xa7CHxS",
        "outputId": "da0f2f0a-6320-4ca8-9a96-a83fcee7068f"
      },
      "source": [
        "# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다\n",
        "# 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n",
        "src_input = tensor[:, :-1]  \n",
        "# tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
        "tgt_input = tensor[:, 1:]    \n",
        "\n",
        "print(src_input[0])\n",
        "print(tgt_input[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   2  290   28   94 4472    3    0    0    0    0    0    0    0    0]\n",
            "[ 290   28   94 4472    3    0    0    0    0    0    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vB-S_4jyDtBl",
        "outputId": "0cb0a45d-20b3-4afc-a9df-dbede88ed387"
      },
      "source": [
        "BUFFER_SIZE = len(src_input)\n",
        "BATCH_SIZE = 256\n",
        "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
        "\n",
        " # tokenizer가 구축한 단어사전 내 7000개와, 여기 포함되지 않은 0:<pad>를 포함하여 7001개\n",
        "VOCAB_SIZE = tokenizer.num_words + 1   \n",
        "\n",
        "# 준비한 데이터 소스로부터 데이터셋을 만듭니다\n",
        "# 데이터셋에 대해서는 아래 문서를 참고하세요\n",
        "# 자세히 알아둘수록 도움이 많이 되는 중요한 문서입니다\n",
        "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
        "\n",
        "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input,test_size=0.2, random_state=42)\n",
        "print(\"Source Train:\", enc_train.shape)\n",
        "print(\"Target Train:\", dec_train.shape)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val))\n",
        "val_dataset = val_dataset.shuffle(BUFFER_SIZE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "print(train_dataset)\n",
        "print(val_dataset)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source Train: (124573, 14)\n",
            "Target Train: (124573, 14)\n",
            "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>\n",
            "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17o5bvS1Kg11"
      },
      "source": [
        "class TextGenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "        #self.bidirectional_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(hidden_size,  return_sequences=True))\n",
        "        #self.bidirectional_2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(hidden_size//2,  return_sequences=True))\n",
        "        #self.linear_1 = tf.keras.layers.Dense(64, activation='relu')\n",
        "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True, stateful=True,\n",
        "                        recurrent_initializer='glorot_uniform')\n",
        "        #self.dropout_1 = tf.keras.layers.Dropout(0.5)\n",
        "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        #self.dropout_2 = tf.keras.layers.Dropout(0.5)\n",
        "        self.linear_2 = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        #out = self.bidirectional_1(out)\n",
        "        #out = self.bidirectional_2(out)\n",
        "        #out = self.linear_1(out)\n",
        "        out = self.rnn_1(out)\n",
        "        #out = self.dropout_1(out)\n",
        "        out = self.rnn_2(out)\n",
        "        #out = self.dropout_2(out)\n",
        "        out = self.linear_2(out)\n",
        "\n",
        "        \n",
        "        return out\n",
        "    \n",
        "embedding_size = 512 #256\n",
        "hidden_size = 1024 #1024\n",
        "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)\n",
        "\n",
        "\n",
        "# "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR0aeBVsy7Nt",
        "outputId": "d4761030-63a1-4d46-a2e1-645410f8a606"
      },
      "source": [
        "# 데이터셋에서 데이터 한 배치만 불러오는 방법입니다.\n",
        "# 지금은 동작 원리에 너무 빠져들지 마세요~\n",
        "for src_sample, tgt_sample in train_dataset.take(1): break\n",
        "\n",
        "# 한 배치만 불러온 데이터를 모델에 넣어봅니다\n",
        "model(src_sample)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 14, 20001), dtype=float32, numpy=\n",
              "array([[[-5.97928411e-05,  4.68720275e-04,  1.83206605e-04, ...,\n",
              "          7.63900971e-05,  1.61503442e-04,  1.70653308e-04],\n",
              "        [-4.44215257e-04,  9.06070170e-04,  2.61260284e-04, ...,\n",
              "          2.02253359e-04,  6.55150448e-04, -5.52685560e-05],\n",
              "        [-3.54783202e-04,  1.25219533e-03,  7.55967540e-06, ...,\n",
              "          4.50817053e-04,  8.54505168e-04, -2.16904111e-04],\n",
              "        ...,\n",
              "        [-6.71780494e-04, -1.19780586e-03, -1.42205763e-03, ...,\n",
              "          3.71088390e-04,  2.26000207e-04,  2.85110636e-05],\n",
              "        [-8.94619210e-04, -1.80343108e-03, -1.07517536e-03, ...,\n",
              "          3.57487821e-04,  2.79753236e-04,  1.97658635e-04],\n",
              "        [-1.12312334e-03, -2.36129877e-03, -7.69935374e-04, ...,\n",
              "          2.66625662e-04,  3.31013143e-04,  3.63632193e-04]],\n",
              "\n",
              "       [[-5.97928411e-05,  4.68720275e-04,  1.83206605e-04, ...,\n",
              "          7.63900971e-05,  1.61503442e-04,  1.70653308e-04],\n",
              "        [-1.46228384e-04,  1.03930943e-03,  4.85611585e-04, ...,\n",
              "         -8.63828463e-05,  6.98060961e-04,  6.76536729e-05],\n",
              "        [ 4.91098799e-05,  1.34318660e-03,  7.43790064e-04, ...,\n",
              "         -4.20417869e-04,  1.00053521e-03, -1.13416645e-04],\n",
              "        ...,\n",
              "        [-2.11044986e-04,  7.76965695e-04,  2.36900337e-03, ...,\n",
              "         -2.98117724e-04,  3.54996417e-04,  7.07747240e-04],\n",
              "        [-2.91326374e-04,  6.90391113e-04,  2.16596620e-03, ...,\n",
              "         -2.39587520e-04,  3.00091226e-04,  7.79143418e-04],\n",
              "        [-4.38418036e-04,  1.38381743e-04,  2.04443280e-03, ...,\n",
              "         -2.79125437e-04,  1.66721933e-04,  8.98985076e-04]],\n",
              "\n",
              "       [[-5.97928411e-05,  4.68720275e-04,  1.83206605e-04, ...,\n",
              "          7.63900971e-05,  1.61503442e-04,  1.70653308e-04],\n",
              "        [-9.71600821e-05,  6.83289836e-04,  5.08954035e-05, ...,\n",
              "         -1.92746375e-05,  1.03553160e-04,  2.22883595e-04],\n",
              "        [-1.97456073e-04,  8.91288277e-04, -5.02600560e-05, ...,\n",
              "         -9.91096313e-05,  6.59178040e-05,  2.74755585e-04],\n",
              "        ...,\n",
              "        [ 1.97859103e-04,  1.04119557e-04, -1.25278730e-03, ...,\n",
              "          1.04570924e-03,  1.42567896e-03, -7.84554984e-04],\n",
              "        [ 9.10084127e-05, -2.53537000e-05, -1.00986520e-03, ...,\n",
              "          1.24342053e-03,  1.46952632e-03, -7.30401312e-04],\n",
              "        [-1.43937039e-04, -3.48341215e-04, -6.08834205e-04, ...,\n",
              "          1.43852143e-03,  1.26415223e-03, -9.53182054e-04]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-5.97928411e-05,  4.68720275e-04,  1.83206605e-04, ...,\n",
              "          7.63900971e-05,  1.61503442e-04,  1.70653308e-04],\n",
              "        [ 5.09582060e-05,  5.82896406e-04,  2.30177175e-04, ...,\n",
              "         -1.18747179e-04,  3.59516038e-04,  8.76445192e-05],\n",
              "        [ 5.02509531e-04,  7.04883656e-04,  1.30240020e-04, ...,\n",
              "         -2.65392562e-04,  3.84977146e-04,  6.99685552e-05],\n",
              "        ...,\n",
              "        [-1.77344598e-03, -3.76145286e-03,  5.76427410e-05, ...,\n",
              "         -4.26297891e-04,  4.78739676e-04,  3.63122934e-04],\n",
              "        [-2.05214228e-03, -4.05035773e-03, -2.77542385e-05, ...,\n",
              "         -7.07132334e-04,  4.13937727e-04,  4.26736020e-04],\n",
              "        [-2.30697240e-03, -4.24973667e-03, -1.41949262e-04, ...,\n",
              "         -1.00591488e-03,  3.45146109e-04,  4.63874050e-04]],\n",
              "\n",
              "       [[-5.97928411e-05,  4.68720275e-04,  1.83206605e-04, ...,\n",
              "          7.63900971e-05,  1.61503442e-04,  1.70653308e-04],\n",
              "        [-8.52973826e-05,  7.07819883e-04,  1.53476940e-04, ...,\n",
              "          2.59674009e-04,  3.28270980e-04,  1.92811262e-04],\n",
              "        [-8.01172791e-05,  1.16330187e-03, -9.41726321e-05, ...,\n",
              "          3.55458498e-04,  3.27158370e-04,  2.16091532e-04],\n",
              "        ...,\n",
              "        [-1.83010846e-03, -3.00647994e-03,  5.33754705e-04, ...,\n",
              "         -4.30550223e-04,  3.88664957e-05,  1.07804127e-03],\n",
              "        [-2.09831120e-03, -3.38262995e-03,  4.72705608e-04, ...,\n",
              "         -6.89078995e-04, -3.57105018e-05,  1.10215670e-03],\n",
              "        [-2.34614220e-03, -3.66904307e-03,  3.70822236e-04, ...,\n",
              "         -9.68836364e-04, -9.21832834e-05,  1.09728123e-03]],\n",
              "\n",
              "       [[-5.97928411e-05,  4.68720275e-04,  1.83206605e-04, ...,\n",
              "          7.63900971e-05,  1.61503442e-04,  1.70653308e-04],\n",
              "        [ 1.76998903e-04,  7.77683512e-04,  3.95653420e-04, ...,\n",
              "         -9.52166811e-05,  2.83455098e-04,  1.53736735e-04],\n",
              "        [ 4.20338212e-04,  5.11276943e-04,  3.93693015e-04, ...,\n",
              "          1.57268340e-04,  3.39963968e-04,  1.89305298e-04],\n",
              "        ...,\n",
              "        [-1.76738342e-03, -3.45439650e-03,  6.76633150e-04, ...,\n",
              "         -4.42920282e-04,  1.57122355e-04,  3.07893119e-04],\n",
              "        [-2.06591678e-03, -3.75205697e-03,  6.07344089e-04, ...,\n",
              "         -6.52021263e-04,  1.25408100e-04,  4.21604636e-04],\n",
              "        [-2.33799289e-03, -3.96530190e-03,  4.98570618e-04, ...,\n",
              "         -8.87141796e-04,  9.90798435e-05,  5.06114447e-04]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-s_2aN4LUmsy",
        "outputId": "3215cd5a-444f-4569-93b0-c67b4bdb7af5"
      },
      "source": [
        "model.summary() #2.5061"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"text_generator_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      multiple                  10240512  \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                multiple                  6295552   \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                multiple                  8392704   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  20501025  \n",
            "=================================================================\n",
            "Total params: 45,429,793\n",
            "Trainable params: 45,429,793\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hR-yJgzLc0u",
        "outputId": "ad7b8bc3-ad25-48d2-8ab2-ca5099e7dd6b"
      },
      "source": [
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer,metrics=['accuracy'])\n",
        "history = model.fit(train_dataset, epochs=10, validation_data=val_dataset)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "486/486 [==============================] - 176s 357ms/step - loss: 3.3347 - accuracy: 0.5007 - val_loss: 3.0493 - val_accuracy: 0.5226\n",
            "Epoch 2/10\n",
            "486/486 [==============================] - 173s 356ms/step - loss: 2.9053 - accuracy: 0.5294 - val_loss: 2.8758 - val_accuracy: 0.5343\n",
            "Epoch 3/10\n",
            "486/486 [==============================] - 173s 356ms/step - loss: 2.6890 - accuracy: 0.5431 - val_loss: 2.7510 - val_accuracy: 0.5467\n",
            "Epoch 4/10\n",
            "486/486 [==============================] - 173s 356ms/step - loss: 2.5001 - accuracy: 0.5590 - val_loss: 2.6638 - val_accuracy: 0.5580\n",
            "Epoch 5/10\n",
            "486/486 [==============================] - 180s 371ms/step - loss: 2.3332 - accuracy: 0.5760 - val_loss: 2.5937 - val_accuracy: 0.5694\n",
            "Epoch 6/10\n",
            "486/486 [==============================] - 173s 356ms/step - loss: 2.1865 - accuracy: 0.5938 - val_loss: 2.5363 - val_accuracy: 0.5801\n",
            "Epoch 7/10\n",
            "486/486 [==============================] - 173s 355ms/step - loss: 2.0549 - accuracy: 0.6117 - val_loss: 2.4951 - val_accuracy: 0.5893\n",
            "Epoch 8/10\n",
            "486/486 [==============================] - 173s 356ms/step - loss: 1.9348 - accuracy: 0.6300 - val_loss: 2.4640 - val_accuracy: 0.5979\n",
            "Epoch 9/10\n",
            "486/486 [==============================] - 173s 355ms/step - loss: 1.8239 - accuracy: 0.6482 - val_loss: 2.4387 - val_accuracy: 0.6053\n",
            "Epoch 10/10\n",
            "486/486 [==============================] - 173s 355ms/step - loss: 1.7213 - accuracy: 0.6660 - val_loss: 2.4160 - val_accuracy: 0.6131\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evtf_5gYz9SX"
      },
      "source": [
        "weights = model.get_layer('embedding').get_weights()[0]\n",
        "vocab = vectorize_layer.get_vocabulary()\n",
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VezJBsan90TE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlrwoaehErvz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-Xj0lP4LjM4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MPV5MTJSaqD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOOQidQ3ZSG4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGSODjNwgJj_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBqbWVp2nBAq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z7YW4fdt4d8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnmb-TX9L0_0"
      },
      "source": [
        "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
        "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
        "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
        "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
        "    end_token = tokenizer.word_index[\"<end>\"]\n",
        "\n",
        "    # 단어 하나씩 예측해 문장을 만듭니다\n",
        "    #    1. 입력받은 문장의 텐서를 입력합니다\n",
        "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
        "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
        "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다\n",
        "    while True:\n",
        "        # 1\n",
        "        predict = model(test_tensor) \n",
        "        # 2\n",
        "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
        "        # 3 \n",
        "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
        "        # 4\n",
        "        if predict_word.numpy()[0] == end_token: break\n",
        "        if test_tensor.shape[1] >= max_len: break\n",
        "\n",
        "    generated = \"\"\n",
        "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
        "    for word_index in test_tensor[0].numpy():\n",
        "        generated += tokenizer.index_word[word_index] + \" \"\n",
        "\n",
        "    return generated"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "9sClUfJTOsIj",
        "outputId": "6e3cf4fb-972d-4d67-de64-6aff76b4ffd3"
      },
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-c106459bfa00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_sentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"<start> i love\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-417ccd0379ee>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(model, tokenizer, init_sentence, max_len)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpredict_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1030\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-b2f43067b58f>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#out = self.bidirectional_2(out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#out = self.rnn_2(out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         training=training_mode):\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m       \u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    268\u001b[0m                              \u001b[0;34m' is incompatible with layer '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                              \u001b[0;34m': expected shape='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m                              ', found shape=' + display_shape(x.shape))\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer lstm: expected shape=(256, None, 64), found shape=(1, 3, 64)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQC9xxUviVmn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PJGKYq4beJw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "ZyQ3ZA9xpjOn",
        "outputId": "f2fd239b-e6d8-4230-8037-f1706aa00f6b"
      },
      "source": [
        "def plot_graphs(history, metric):\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.plot(history.history['val_'+metric], '')\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([metric, 'val_'+metric])\n",
        "  plt.show()\n",
        "plot_graphs(history, 'loss')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9vwUQca7GTf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fouUw0ljB9wr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3DF_YAD0OHa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fTq70GnWeCo"
      },
      "source": [
        "while True:pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iT9CipEqE_z"
      },
      "source": [
        "*set의 원소는 iterator를 만들어서 next로 가져온다...\n",
        "set은 시퀀스 자료형 이아니기 때문에 인덱싱이 안된다~!~!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqWwSacdtWqT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIxKvNUR5I4x",
        "outputId": "ce4b55e0-f0a5-4010-991a-539bb7c1f51e"
      },
      "source": [
        "model.summary() #2.5061"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"text_generator_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     multiple                  10240512  \n",
            "_________________________________________________________________\n",
            "lstm_18 (LSTM)               multiple                  6295552   \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             multiple                  20501025  \n",
            "=================================================================\n",
            "Total params: 37,037,089\n",
            "Trainable params: 37,037,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Htbd4lzY3fgr",
        "outputId": "377e7c05-c8f9-4b5f-98f9-7275609d3c72"
      },
      "source": [
        "model.summary()     #2.4497"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"text_generator_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     multiple                  10240512  \n",
            "_________________________________________________________________\n",
            "lstm_17 (LSTM)               multiple                  6295552   \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             multiple                  20501025  \n",
            "=================================================================\n",
            "Total params: 37,037,089\n",
            "Trainable params: 37,037,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmzAVAVcLL10",
        "outputId": "a4a23edb-db3c-4117-ab28-0d0c91e78499"
      },
      "source": [
        "model.summary()    #2.6248 "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"text_generator_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      multiple                  10240512  \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                multiple                  6295552   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                multiple                  8392704   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  20501025  \n",
            "=================================================================\n",
            "Total params: 45,429,793\n",
            "Trainable params: 45,429,793\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}